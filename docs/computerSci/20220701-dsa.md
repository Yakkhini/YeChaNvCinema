# 数据结构及算法学习及笔记

## 数据结构（基础）- 邓俊辉

经过比对国内外课程与教材，我决定使用邓俊辉的课程及教材来学习数据结构和算法。

MOOC 网站：[数据结构 (上) - 清华大学 - 学堂在线](https://www.xuetangx.com/course/THU08091000384/10322765?channel=i.area.course_list_all)

教材第三版：[dsacpp-3rd-edn.pdf](https://cloud.tsinghua.edu.cn/d/76cbab99574046698804/files/?p=%2Fdsacpp-3rd-edn.pdf)

其他教学资料：[DSACPP](https://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/index.htm)

### 绪论

计算：通过掌握规律和技巧来更高效、低耗地满足目标

测度：衡量算法性能

算法分析：正确性，**成本**

成本：时间，空间成本，怎样度量

衡量的关键：问题实例的 **规模**

但是同一算法等规模，不同实例的成本可能相差很大。所以要考虑 **最坏情况** 更加稳妥。

解决同一个问题往往有很多算法，但影响算法的性能也有很多区别。所以要抽象一个理想的平台来衡量算法。

图灵机：理想模型。由格子、字符、读写头组成，读写头按节拍移动，每个节拍都使图灵机可以有一种状态。状态的转换由转换函数决定。

RAM 模型：视作无限空间（寄存器），是对计算工具的抽象和简化，可以更好地衡量性能。（用操作步数衡量时间，忽略硬件差异）

#### 渐进复杂度

大 $O$ 记号：不拘泥于细节，而看算法的规模（数量级）。因为计算成本需要计算足够大的问题。

渐进分析：问题规模足够大时，计算成本如何增长

问题规模与时间空间： $n \sim T(n) \sim S(n)$

常数项可忽略，低次项可忽略

* 大 $O$ 上界，**最常用，悲观估计**
* $\Omega$ 下界
* $\Theta$ 确界

常数复杂度：$O(1)$。一般不含循环、转向、递归，与 $n$ 无关。

对数复杂度：$O(\log^c n)$，底数无所谓，常数次幂无所谓，**复杂度无限接近常数。**

多项式复杂度：$O(n^c)$，依然有效。

指数复杂度：$O(2^n)$，**不可忍受的难解问题，指数复杂度为无效算法。**

#### 复杂度分析

算法分析的复杂度确定是一种估算。

要确定负责度，需要将算法改为 RAM 基本指令，不过不用精确统计。

迭代：级数求和
递归：递归跟踪，递推方程

级数

* 算数级数：末项平方。
* 幂方级数：比幂方多一阶。
* 几何级数：与末项同阶。
* 收敛级数：$O(1)$

#### 迭代与递归

递归的方式不一定是最好的方案，看似笨拙的迭代有时更好

递归的核心思想：**分而治之**

减而治之（Decrease and Conquer）：分解问题为平凡问题与另一个缩减规模的问题。

检查递归可以使用递归跟踪。

对于更复杂的递归，使用递推方程来把握。

分而治之：将问题分为两个规模相当的子问题，在最终合并。

大师定理（MasterTheory）：原理是看结果的哪个部分权重更高。

#### 动态规划

让算法运转、保持正确、更快速。

更快速的方法：递归初步解，给出迭代。

例：Fibnacci 数列

递归中存在很多重复的计算，那么就会让性能更差。

解决方法：记忆化（制表），颠倒计算方向（改为自底向上迭代）。

LCS：Longest Common Subsequence

LeetCode：[Longest Common Subsequence - LeetCode](https://leetcode.com/problems/longest-common-subsequence/)

```go
func longestCommonSubsequence(text1 string, text2 string) int {
    len1 := len(text1) + 1
    len2 := len(text2) + 1
    
    point := make([][]int, len1)
    
    for i := range point {
        point[i] = make([]int, len2)
    }
    
    for i := 0; i < len1; i++ {
        for j := 0; j < len2; j++ {
            if i == 0 || j == 0 {
                point[i][j] = 0
            } else {
                if text1[i-1] == text2[j-1] {
                    point[i][j] = point[i-1][j-1] + 1
                } else {
                    if point[i-1][j] > point[i][j-1] {
                        point[i][j] = point[i-1][j]
                    } else {
                        point[i][j] = point[i][j-1]
                    }
                }
            }
        }
    }

    return point[len1 - 1][len2 - 1]
}

```

#### 局限

更易得的临时空间。

所以在计算机上，并不一定复杂度更小的算法运算更快。操作系统的性能与数据的访问方式也有关系，当访问更有序时，缓存更容易处理和优化计算过程；而当访问比较混沌和随机时，缓存与 IO 操作可能更频繁，因此实际上对硬件负担变大了。

我个人的看法是，当比较复杂度相近、在同一数量级的算法时，缓存和硬件带来的影响就应该被考虑进去。不过这种规律与先前学的知识并不矛盾，因为我们在抽象为 RAM 机器时就忽略了硬件性能的影响。在实际工作业务或竞赛中，如果对算法性能要求更高、更精细，锱铢必较，那么在必要的时候将硬件与操作系统的客观条件考虑进来也是没关系的。

### 向量

#### 抽象数据类型

向量是线性结构

抽象数据类型（ADT）：模型 + 操作

数据结构：基于某种语言，实现 ADT 规范的算法

向量 ADT：循秩访问

#### 可扩充向量

动态空间管理：即将发生上溢时，适当扩充容量。

递增扩容：每次扩容增加一定数值。总体耗时 $O(n^2)$，每次 $O(n)$

加倍扩容：每次与旧容量成倍、成比例扩充容量。总体耗时 $O(n)$，每次 $O(1)$，**用空间换时间。**

平均复杂度：各种操作的概率分布，做总体的加权平均，**割裂了操作的相关性。**

分摊复杂度：连续多次操作，再分摊。**更真实地接触实际操作情况。**

#### 无序向量

#### 有序向量：唯一化

有序向量相对无序向量，还可以比较元素大小，且逆序对为 $0$。

无需每次调用 `remove()` 函数，而是挪到后面统一处理，避免重复操作。

#### 有序向量：二分查找 - A

对于有序向量，不必使用遍历查找，使用二分法即可。

#### 有序向量：Fib 查找

Fibonacci 查找：改进算法，因为左右递归深度不应该相同。

这是因为在二分查找中，向左需要一次比较，向右需要两次比较，每次转向的方向不同成本也不同。所以如果把分割点适当右移时，结果出现在左侧的概率更高，向左转向的可能更大，因而总体成本较低。但是，如果分割点过于靠右，那么分割的效率就会变差（如果到最右，那就又变成了遍历查找）。所以需要找到一个最合理的分割点。经过数学计算，发现这个点就是黄金分割点。

#### 有序向量：二分查找 - B

牺牲直接命中的结果，使左右转向平衡。从结果来看，原先最好结果需要计算时间更长了，原先最差结果需要计算时间变得很短（减倍），使不同的情况性能接近，算法表现更加稳定。

#### 有序向量：二分查找 - C

进一步取消右侧的闭口开端，不必做显式判断，只需找到最终的边界。

但是这样应该会有一种缺点：如果要查找的元素并不存在于向量中，仍然会返回一个错误的结果。但是如果用于插值，那么这样的结果没有影响。

#### 有序向量：插值查找

如果受到局部干扰，加上乘法、除法，有时性能耗费更高。所以应当与二分查找相配合。

#### 起泡排序

扫描逆序对并交换回来，直至全序

算术级数，所以 $O(n^2)$

#### 归并排序

将向量递归分解，再逐步归并。（采用 **二路归并** 的方式）

#### 位图 - Bitmap

略

#### 例题：LeetCode - 2250

Count Number of Rectangles Containing Each Point

<!-- tabs:start -->

#### **描述**

You are given a 2D integer array $\tt{rectangles}$ where $\tt{rectangles[i] = [l_{i}, h_{i}]}$ indicates that ith rectangle has a length of $\tt{l_{i}}$ and a height of $\tt{h_{i}}$. You are also given a 2D integer array $\tt{points where points[j] = [x_{j}, y_{j}]}$ is a point with coordinates $\tt{(x_{j}, y_{j})}$.

The ith rectangle has its bottom-left corner point at the coordinates $\tt{(0, 0)}$ and its top-right corner point at $\tt{(l_{i}, h_{i})}$.

Return an integer array $\tt{count}$ of length points.length where $\tt{count[j]}$ is the number of rectangles that contain the $\tt{j_{th}}$ point.

The $\tt{i_{th}}$ rectangle contains the $\tt{j_{th}}$ point if $\tt{0 \leqslant x_{j} \leqslant l_{i}}$ and $\tt{0 \leqslant y_{j} \leqslant h_{i}}$. Note that points that lie on the edges of a rectangle are also considered to be contained by that rectangle.

#### **案例 1**

```
Input: rectangles = [[1,2],[2,3],[2,5]], points = [[2,1],[1,4]]
Output: [2,1]
Explanation: 
The first rectangle contains no points.
The second rectangle contains only the point (2, 1).
The third rectangle contains the points (2, 1) and (1, 4).
The number of rectangles that contain the point (2, 1) is 2.
The number of rectangles that contain the point (1, 4) is 1.
Therefore, we return [2, 1].
```

#### **案例 2**

```
Input: rectangles = [[1,1],[2,2],[3,3]], points = [[1,3],[1,1]]
Output: [1,3]
Explanation:
The first rectangle contains only the point (1, 1).
The second rectangle contains only the point (1, 1).
The third rectangle contains the points (1, 3) and (1, 1).
The number of rectangles that contain the point (1, 3) is 1.
The number of rectangles that contain the point (1, 1) is 3.
Therefore, we return [1, 3].
```

#### **约束**

* $\tt{1 \leqslant rectangles.length, points.length \leqslant 5 * 10^4}$
* $\tt{rectangles[i].length = points[j].length = 2}$
* $\tt{1 \leqslant l_i, x_j \leqslant 10^9}$
* $\tt{1 \leqslant h_i, y_j \leqslant 100}$
* $\texttt{All the rectangles are unique.}$
* $\texttt{All the points are unique.}$

#### **答案**

```go
/*
 * @lc app=leetcode id=2250 lang=golang
 *
 * [2250] Count Number of Rectangles Containing Each Point
 */

package quiz2250

// @lc code=start

import "sort"

func countRectangles(rectangles [][]int, points [][]int) []int {

	result := make([]int, len(points))

	table := make([][]int, 100)

	for _, v := range rectangles {
		table[v[1]-1] = append(table[v[1]-1], v[0])
	}

	for _, v := range table {
		sort.Ints(v)
	}

	for i, v := range points {
		for _, subtable := range table[v[1]-1:] {
			if len(subtable) == 0 {
				continue
			}

			for lo, hi, long := 0, len(subtable), len(subtable); ; {
				var mi int = (lo + hi) / 2

				if subtable[mi] < v[0] {
					lo = mi + 1
				} else {
					hi = mi
				}

				if hi-lo == 0 {
					result[i] += long - hi
					break
				}
			}
		}
	}

	return result
}

// @lc code=end

```

运行结果：

**Accepted**
* 47/47 cases passed (470 ms)
* Your runtime beats 90.91 % of golang submissions
* Your memory usage beats 90.91 % of golang submissions (15.7 MB)

<!-- tabs:end -->

##### 第一次解析：写一个可以工作的代码

```go
// @lc code=start
func countRectangles(rectangles [][]int, points [][]int) []int {

	result := make([]int, len(points))

    for i, poi := range points {
		for _, rec := range rectangles {
			if poi[0] <= rec[0] && poi[1] <=rec[1] {
				result[i] += 1
			}
		}
	}

	return result
}
// @lc code=end
```

这个代码比较直观，每一个点都遍历所有的矩形做比较。那么，这种比较的时间复杂度与输入的数据内容无关，只与矩形和点的输入数据量有关。如果输入 n 个矩形，m 个点，那么时间复杂度应当是 $O(nm)$。

##### 寻找优化空间

但是首先可以工作的第一版算法是比较差的，在测试中甚至无法通过数据量较大的测试案例。所以就应该考虑优化空间，是否有重复的比较。

根据矩形的性质，我们不难发现：

* 如果某一个点在一矩形外，那么所有小于这个矩形的矩形都无法包含这个点
* 同样的，如果某一个点在矩形内，那么所有横纵坐标均小于这个点的其他点也包含在矩形内
* 进一步的，如果一个点的横座标或者纵座标大于某个矩形角点的横座标或者纵座标，那么这个点必然在矩形外；也必然在所有角点横座标更小或者纵座标更小的矩形之外

所以说，想要优化本题，重点在于 **排序和查找**。如果处理数据的矩形、点或二者都按大小顺序排列，那么在比较一次后就可以自动推出一系列其他矩形是否能包含点，或者一系列其他点是否在矩形内。

由于所要求的输出数据是按输入点的顺序排列，所以更倾向于将输入的矩形重新排列，因为这样不会对结果的顺序造成影响，增加不必要的排序工作。

如果在排序时考虑矩形的宽和高，那么排序会有一定困难：有时候两个矩形之间，一个更宽更矮，一个更高更窄，那么这两个矩形之间的顺序关系是不清楚的，除此之外，每次比较都需要耗费两步操作。不过，也可以采用把每个严格大于或小于的矩形分组，大家可以自行探究。

所以，我们需要对矩形，按长或宽做一个排序。不过这样虽然会省去一些比较的时间，但是真的能减少计算复杂度，节约时间吗？答案是否定的。

我们假设矩形的长宽都为随机数，留给我们的排序方式有：

* 冒泡排序，时间复杂度 $O(n^2)$
* 选择排序，与冒泡排序相同。
* 插值排序，时间复杂度 $O(n^2)$

表面上看，在考虑排序的性能开销后，与直接遍历的时间复杂度数量级不相上下，优化空间不大；如果真的给出数据集中点和矩阵都是随机的，那么确实是这样。但是其实我们得到的数据是有一定规律的：

$$1 \leqslant h_i, y_j \leqslant 100$$

这条约束有什么用呢？这与冒泡排序（选择排序）与插值排序内部的实现有关。在冒泡排序（选择排序中），每次选出的元素可以看作或等效于一个画家算法选出的，即需要一个遍历的操作，与被遍历向量的长度有关。也就是说，只要选用了这种排序方式，无论被排序的数据类型有多少种，都对算法无影响，而只会与给出矩形的数量有关。这是我们不愿意看到的。

那么插值排序呢？插值排序在从原向量中拿取元素的方式是顺序拿取，这一部分的性能开销可以忽略不计。而在插值时，是在一个 **有序向量** 中查找位置并插入数据。这就给我们带来了优化的空间：我们完全可以通过将等高的矩形归类，来把这个有序向量的元素量缩减到 $100$ 以内。那么，无论有多少矩形，最后在插值时最差也是在 $100$ 个元素中做二分查找 $O(\log(100)) \approx O(1)$，时间复杂度来到了常数，算上拿取过程整个排序过程复杂度为 $O(n)$。这样的性能开销是完全可以接受的。

而在点的比较时，每一次比较首先在一个必小于 $100$ 的向量中做二分，性能开销为常数；接着在所有高于此点的矩形做遍历，时间复杂度的数量级依然为 $O(nm)$，但是显著缩减了一些不必要的比较。

那么，是否还有进一步的优化空间呢？

是有的。我们注意到点在比较中，虽然不再与比它高度更低的矩形相比较，但仍在高度比它高的矩形中做遍历。

我们完全可以将等高的矩形分组后，按宽度插值排列。这一步的数量级为 $O(\log_2\frac{n}{100})$。估算比较简单，我特地标注出分母是说明这样的性能开销很小，完全可以接受；同时这一步的排序在之后每一个点的比较中都可以复用，收益为正。那么排序的时间复杂度就升到了 $O(n\log{n})$，但是之后点的处理中，时间复杂度也降到了 $O(m \log{n})$。虽然一升一降，但提升了算法内部的性能稳定性，而且我们知道有一部分计算的结果被复用了，收益是正的。

想法很好，但是如果你真的上手按这个思路写，结果会很差。这是因为插值不适用于列表排序。实际上，这种情况更适合用 **快速排序**。但由于我们还没有学到快速排序，所以先使用 `sort` 包来做这件事。

最终我们得到了答案。我建议你亲自做一遍再看答案，因为代码的一些细枝末节（比如二分查找的书写）其实并不像它看起来这么简单。甚至于对这道题来说，二分法也是它的考点之一。

### 列表

模仿向量的循秩访问，同样是 **线性结构**

特点：存储空间的分配是动态的。特点：**静态操作开销大，动态操作开销小，与向量相反。**

节点：node，前后互为前驱后继，**物理上不一定连续，但在逻辑上为线性。**第一个是首节点，最后一个是末节点。

循秩访问：依次查找，需要从头或尾出发，$O(n)$

所以应当循位置访问。

#### 无序列表

插入：新建节点，修改前后驱。哨兵节点保证操作安全

删除：使前后驱节点连接跳过待删除节点

析构：删除所有对外节点后删除哨兵

#### 有序列表

查找性能开销较大。这是因为根本上列表是循位置访问，无法做到随机访问。

#### 选择排序

是冒泡排序的改进，比如每次找出最大的放在最后，而不必一次一次挪。

时间复杂度为 $\Theta(n^2)$

虽然数量级不变，但是在实际处理过程中免去了很多移动数据的环节，所以还是有比较大的提升的。

#### 插入排序

原序列中按顺序取出（比如不再寻找最大的一项），插入到输出序列中的合序位置。

复杂度主要还是取决于插入的操作，复杂度

$$ \frac{1}{2} + \frac{2}{2} + \frac{3}{2} + \dots + \frac{n}{2} \approx O( \frac{n^2}{2}) \approx O(n^2)  $$

虽然复杂度的数量级相同，但是插入排序应当是要比选择排序好些的，因为画家算法每一次比较都需要遍历所有元素，而插入排序只需要找到一个合序位置即可。

### 栈与队列

栈 **先进后出**，队列 **先进先出**

#### 进制转换

#### 括号匹配

优势：在不同括号甚至匹配字段混用时，依然可以在一次扫描中厘清嵌套关系。