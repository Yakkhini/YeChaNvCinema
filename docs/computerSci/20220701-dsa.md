# 数据结构及算法学习及笔记

## 数据结构（基础）- 邓俊辉

经过比对国内外课程与教材，我决定使用邓俊辉的课程及教材来学习数据结构和算法。

MOOC 网站：[数据结构 (上) - 清华大学 - 学堂在线](https://www.xuetangx.com/course/THU08091000384/10322765?channel=i.area.course_list_all)

教材第三版：[dsacpp-3rd-edn.pdf](https://cloud.tsinghua.edu.cn/d/76cbab99574046698804/files/?p=%2Fdsacpp-3rd-edn.pdf)

其他教学资料：[DSACPP](https://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/index.htm)

### 绪论

计算：通过掌握规律和技巧来更高效、低耗地满足目标

测度：衡量算法性能

算法分析：正确性，**成本**

成本：时间，空间成本，怎样度量

衡量的关键：问题实例的 **规模**

但是同一算法等规模，不同实例的成本可能相差很大。所以要考虑 **最坏情况** 更加稳妥。

解决同一个问题往往有很多算法，但影响算法的性能也有很多区别。所以要抽象一个理想的平台来衡量算法。

图灵机：理想模型。由格子、字符、读写头组成，读写头按节拍移动，每个节拍都使图灵机可以有一种状态。状态的转换由转换函数决定。

RAM 模型：视作无限空间（寄存器），是对计算工具的抽象和简化，可以更好地衡量性能。（用操作步数衡量时间，忽略硬件差异）

#### 渐进复杂度

大 $O$ 记号：不拘泥于细节，而看算法的规模（数量级）。因为计算成本需要计算足够大的问题。

渐进分析：问题规模足够大时，计算成本如何增长

问题规模与时间空间： $n \sim T(n) \sim S(n)$

常数项可忽略，低次项可忽略

* 大 $O$ 上界，**最常用，悲观估计**
* $\Omega$ 下界
* $\Theta$ 确界

常数复杂度：$O(1)$。一般不含循环、转向、递归，与 $n$ 无关。

对数复杂度：$O(\log^c n)$，底数无所谓，常数次幂无所谓，**复杂度无限接近常数。**

多项式复杂度：$O(n^c)$，依然有效。

指数复杂度：$O(2^n)$，**不可忍受的难解问题，指数复杂度为无效算法。**

#### 复杂度分析

算法分析的复杂度确定是一种估算。

要确定负责度，需要将算法改为 RAM 基本指令，不过不用精确统计。

迭代：级数求和
递归：递归跟踪，递推方程

级数

* 算数级数：末项平方。
* 幂方级数：比幂方多一阶。
* 几何级数：与末项同阶。
* 收敛级数：$O(1)$

#### 迭代与递归

递归的方式不一定是最好的方案，看似笨拙的迭代有时更好

递归的核心思想：**分而治之**

减而治之（Decrease and Conquer）：分解问题为平凡问题与另一个缩减规模的问题。

检查递归可以使用递归跟踪。

对于更复杂的递归，使用递推方程来把握。

分而治之：将问题分为两个规模相当的子问题，在最终合并。

大师定理（MasterTheory）：原理是看结果的哪个部分权重更高。

#### 动态规划

让算法运转、保持正确、更快速。

更快速的方法：递归初步解，给出迭代。

例：Fibnacci 数列

递归中存在很多重复的计算，那么就会让性能更差。

解决方法：记忆化（制表），颠倒计算方向（改为自底向上迭代）。

LCS：Longest Common Subsequence

LeetCode：[Longest Common Subsequence - LeetCode](https://leetcode.com/problems/longest-common-subsequence/)

```go
func longestCommonSubsequence(text1 string, text2 string) int {
    len1 := len(text1) + 1
    len2 := len(text2) + 1
    
    point := make([][]int, len1)
    
    for i := range point {
        point[i] = make([]int, len2)
    }
    
    for i := 0; i < len1; i++ {
        for j := 0; j < len2; j++ {
            if i == 0 || j == 0 {
                point[i][j] = 0
            } else {
                if text1[i-1] == text2[j-1] {
                    point[i][j] = point[i-1][j-1] + 1
                } else {
                    if point[i-1][j] > point[i][j-1] {
                        point[i][j] = point[i-1][j]
                    } else {
                        point[i][j] = point[i][j-1]
                    }
                }
            }
        }
    }

    return point[len1 - 1][len2 - 1]
}

```

#### 局限

更易得的临时空间。

所以在计算机上，并不一定复杂度更小的算法运算更快。操作系统的性能与数据的访问方式也有关系，当访问更有序时，缓存更容易处理和优化计算过程；而当访问比较混沌和随机时，缓存与 IO 操作可能更频繁，因此实际上对硬件负担变大了。

我个人的看法是，当比较复杂度相近、在同一数量级的算法时，缓存和硬件带来的影响就应该被考虑进去。不过这种规律与先前学的知识并不矛盾，因为我们在抽象为 RAM 机器时就忽略了硬件性能的影响。在实际工作业务或竞赛中，如果对算法性能要求更高、更精细，锱铢必较，那么在必要的时候将硬件与操作系统的客观条件考虑进来也是没关系的。

### 向量

#### 抽象数据类型

向量是线性结构

抽象数据类型（ADT）：模型 + 操作

数据结构：基于某种语言，实现 ADT 规范的算法

向量 ADT：循秩访问

#### 可扩充向量

动态空间管理：即将发生上溢时，适当扩充容量。

递增扩容：每次扩容增加一定数值。总体耗时 $O(n^2)$，每次 $O(n)$

加倍扩容：每次与旧容量成倍、成比例扩充容量。总体耗时 $O(n)$，每次 $O(1)$，**用空间换时间。**

平均复杂度：各种操作的概率分布，做总体的加权平均，**割裂了操作的相关性。**

分摊复杂度：连续多次操作，再分摊。**更真实地接触实际操作情况。**

#### 无序向量

#### 有序向量：唯一化

有序向量相对无序向量，还可以比较元素大小，且逆序对为 0。

无需每次调用 `remove()` 函数，而是挪到后面统一处理，避免重复操作。

#### 有序向量：二分查找 - A

对于有序向量，不必使用遍历查找，使用二分法即可。

#### 有序向量：Fib 查找

Fibonacci 查找：改进算法，因为左右递归深度不应该相同。

这是因为在二分查找中，向左需要一次比较，向右需要两次比较，每次转向的方向不同成本也不同。所以如果把分割点适当右移时，结果出现在左侧的概率更高，向左转向的可能更大，因而总体成本较低。但是，如果分割点过于靠右，那么分割的效率就会变差（如果到最右，那就又变成了遍历查找）。所以需要找到一个最合理的分割点。经过数学计算，发现这个点就是黄金分割点。

#### 有序向量：二分查找 - B

牺牲直接命中的结果，使左右转向平衡。从结果来看，原先最好结果需要计算时间更长了，原先最差结果需要计算时间变得很短（减倍），使不同的情况性能接近，算法表现更加稳定。

#### 有序向量：二分查找 - C

进一步取消右侧的闭口开端，不必做显式判断，只需找到最终的边界。

但是这样应该会有一种缺点：如果要查找的元素并不存在于向量中，仍然会返回一个错误的结果。但是如果用于插值，那么这样的结果没有影响。

#### 有序向量：插值查找

如果受到局部干扰，加上乘法、除法，有时性能耗费更高。所以应当与二分查找相配合。

#### 起泡排序

扫描逆序对并交换回来，直至全序

算术级数，所以 $O(n^2)$

#### 归并排序

将向量递归分解，再逐步归并。（采用 **二路归并** 的方式）

#### 位图 - Bitmap

略
