# 数据结构及算法学习及笔记

## 数据结构（基础）- 邓俊辉

经过比对国内外课程与教材，我决定使用邓俊辉的课程及教材来学习数据结构和算法。

MOOC 网站：[数据结构 (上) - 清华大学 - 学堂在线](https://www.xuetangx.com/course/THU08091000384/10322765?channel=i.area.course_list_all)

教材第三版：[dsacpp-3rd-edn.pdf](https://cloud.tsinghua.edu.cn/d/76cbab99574046698804/files/?p=%2Fdsacpp-3rd-edn.pdf)

其他教学资料：[DSACPP](https://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/index.htm)

### 绪论

计算：通过掌握规律和技巧来更高效、低耗地满足目标

测度：衡量算法性能

算法分析：正确性，**成本**

成本：时间，空间成本，怎样度量

衡量的关键：问题实例的 **规模**

但是同一算法等规模，不同实例的成本可能相差很大。所以要考虑 **最坏情况** 更加稳妥。

解决同一个问题往往有很多算法，但影响算法的性能也有很多区别。所以要抽象一个理想的平台来衡量算法。

图灵机：理想模型。由格子、字符、读写头组成，读写头按节拍移动，每个节拍都使图灵机可以有一种状态。状态的转换由转换函数决定。

RAM 模型：视作无限空间（寄存器），是对计算工具的抽象和简化，可以更好地衡量性能。（用操作步数衡量时间，忽略硬件差异）

#### 渐进复杂度

大 $O$ 记号：不拘泥于细节，而看算法的规模（数量级）。因为计算成本需要计算足够大的问题。

渐进分析：问题规模足够大时，计算成本如何增长

问题规模与时间空间： $n \sim T(n) \sim S(n)$

常数项可忽略，低次项可忽略

* 大 $O$ 上界，**最常用，悲观估计**
* $\Omega$ 下界
* $\Theta$ 确界

常数复杂度：$O(1)$。一般不含循环、转向、递归，与 $n$ 无关。

对数复杂度：$O(\log^c n)$，底数无所谓，常数次幂无所谓，**复杂度无限接近常数。**

多项式复杂度：$O(n^c)$，依然有效。

指数复杂度：$O(2^n)$，**不可忍受的难解问题，指数复杂度为无效算法。**

#### 复杂度分析

算法分析的复杂度确定是一种估算。

要确定负责度，需要将算法改为 RAM 基本指令，不过不用精确统计。

迭代：级数求和
递归：递归跟踪，递推方程

级数

* 算数级数：末项平方。
* 幂方级数：比幂方多一阶。
* 几何级数：与末项同阶。
* 收敛级数：$O(1)$

#### 迭代与递归

递归的方式不一定是最好的方案，看似笨拙的迭代有时更好

递归的核心思想：**分而治之**

减而治之（Decrease and Conquer）：分解问题为平凡问题与另一个缩减规模的问题。

检查递归可以使用递归跟踪。

对于更复杂的递归，使用递推方程来把握。

分而治之：将问题分为两个规模相当的子问题，在最终合并。

大师定理（MasterTheory）：原理是看结果的哪个部分权重更高。

#### 动态规划

让算法运转、保持正确、更快速。

更快速的方法：递归初步解，给出迭代。

例：Fibnacci 数列

递归中存在很多重复的计算，那么就会让性能更差。

解决方法：记忆化（制表），颠倒计算方向（改为自底向上迭代）。

LCS：Longest Common Subsequence

LeetCode：[Longest Common Subsequence - LeetCode](https://leetcode.com/problems/longest-common-subsequence/)

```go
func longestCommonSubsequence(text1 string, text2 string) int {
    len1 := len(text1) + 1
    len2 := len(text2) + 1
    
    point := make([][]int, len1)
    
    for i := range point {
        point[i] = make([]int, len2)
    }
    
    for i := 0; i < len1; i++ {
        for j := 0; j < len2; j++ {
            if i == 0 || j == 0 {
                point[i][j] = 0
            } else {
                if text1[i-1] == text2[j-1] {
                    point[i][j] = point[i-1][j-1] + 1
                } else {
                    if point[i-1][j] > point[i][j-1] {
                        point[i][j] = point[i-1][j]
                    } else {
                        point[i][j] = point[i][j-1]
                    }
                }
            }
        }
    }

    return point[len1 - 1][len2 - 1]
}

```

#### 局限

更易得的临时空间。

所以在计算机上，并不一定复杂度更小的算法运算更快。操作系统的性能与数据的访问方式也有关系，当访问更有序时，缓存更容易处理和优化计算过程；而当访问比较混沌和随机时，缓存与 IO 操作可能更频繁，因此实际上对硬件负担变大了。

我个人的看法是，当比较复杂度相近、在同一数量级的算法时，缓存和硬件带来的影响就应该被考虑进去。不过这种规律与先前学的知识并不矛盾，因为我们在抽象为 RAM 机器时就忽略了硬件性能的影响。在实际工作业务或竞赛中，如果对算法性能要求更高、更精细，锱铢必较，那么在必要的时候将硬件与操作系统的客观条件考虑进来也是没关系的。
